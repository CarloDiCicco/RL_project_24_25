"""
eval_suite.py

Standardized checkpoint evaluation: run fixed-seed episodes,
save rewards, plots (boxplot, histogram), rollout video/GIF,
and model snapshots with metadata.
"""

import os, json, shutil, glob, math
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import gymnasium as gym
from gymnasium.wrappers import RecordVideo
from matplotlib.ticker import MaxNLocator
from utils.logging import setup_logger
from utils.video import mp4_to_gif  # <-- new helper

def _format_title(algo: str, env_id: str, frac_label: str, base: str) -> str:
    """
    Compact, single-line title (no wrapping).
    Example: "25% — Trained vs Random (SAC, HalfCheetah-v5)"
    """
    left = f"{frac_label} — " if frac_label else ""
    return f"{left}{base} ({algo}, {env_id})"

def _plot_hist(data, out_path: str, title: str):
    """Histogram with mean/median markers, denser x ticks, outside legend (top-right)."""
    data = np.asarray(data, dtype=float)
    mean = float(np.mean(data))
    median = float(np.median(data))

    fig, ax = plt.subplots(figsize=(8.6, 5.0), constrained_layout=True)
    ax.hist(data, bins=20, edgecolor="black", alpha=0.7)
    ax.axvline(mean,   linestyle="--", linewidth=1.5, label=f"Mean = {mean:.1f}")
    ax.axvline(median, linestyle="-.", linewidth=1.5, label=f"Median = {median:.1f}")

    ax.set_xlabel("Episodic return (per-episode sum; horizon=1,000)")
    ax.set_ylabel("Count (episodes)")
    ax.set_title(title, fontsize=11, pad=6)
    ax.grid(True, axis="y", alpha=0.25)

    # More x ticks for readability
    ax.xaxis.set_major_locator(MaxNLocator(nbins=10))

    # Legend outside, top-right (tight)
    ax.legend(loc="upper left", bbox_to_anchor=(1.01, 1.0), borderaxespad=0., frameon=False)

    fig.savefig(out_path, dpi=120)
    plt.close(fig)

def _plot_box_vs_random(trained_rewards, random_rewards, out_path: str, title: str):
    """Boxplot with per-episode returns; μ±σ just below x labels with a small gap."""
    tr = np.asarray(trained_rewards, dtype=float)
    rnd = np.asarray(random_rewards, dtype=float)

    fig, ax = plt.subplots(figsize=(9.6, 5.4))
    ax.boxplot([tr, rnd], labels=["Trained policy", "Random policy"], showmeans=True)

    ax.set_ylabel("Episodic return (per-episode sum; horizon=1,000)")
    ax.set_title(title, fontsize=11, pad=6)
    ax.grid(True, axis="y", alpha=0.25)

    means = [float(np.mean(tr)), float(np.mean(rnd))]
    stds  = [float(np.std(tr)),  float(np.std(rnd))]
    trans = ax.get_xaxis_transform()

    # A hair lower than before to avoid touching the tick labels
    y_annot = -0.065
    for i, (m, s) in enumerate(zip(means, stds), start=1):
        ax.text(i, y_annot, f"μ={m:.1f}, σ={s:.1f}",
                transform=trans, ha="center", va="top", fontsize=10, color="0.25")

    fig.savefig(out_path, dpi=120, bbox_inches="tight", pad_inches=0.10)
    plt.close(fig)

def _ensure_ffmpeg_env():
    """Make Gymnasium/RecordVideo use the ffmpeg binary from imageio-ffmpeg when not on PATH."""
    try:
        import imageio_ffmpeg, os
        os.environ.setdefault("IMAGEIO_FFMPEG_EXE", imageio_ffmpeg.get_ffmpeg_exe())
    except Exception:
        pass


def _record_one_rollout(agent, env_id: str, seed: int, video_out: str):
    """
    Record a single episode to MP4 using Gymnasium's RecordVideo.
    We create a temporary folder (RecordVideo creates numbered files) and then
    move/rename the resulting mp4 to `video_out`.
    """
    _ensure_ffmpeg_env()
    tmp_dir = str(Path(video_out).with_suffix("").parent / "__tmp_video__")
    os.makedirs(tmp_dir, exist_ok=True)

    # For MuJoCo/Gymnasium you generally need render_mode="rgb_array" for video
    base_env = gym.make(env_id, render_mode="rgb_array")
    env = RecordVideo(base_env, video_folder=tmp_dir, name_prefix="rollout", episode_trigger=lambda i: True)

    # Run exactly one episode with the given seed
    obs, _ = env.reset(seed=seed)
    done = False
    while not done:
        action, _ = agent.predict(obs, deterministic=True)
        obs, r, terminated, truncated, _ = env.step(action)
        done = bool(terminated or truncated)

    env.close()

    # Find the generated mp4 and move it to the desired path
    mp4_list = glob.glob(os.path.join(tmp_dir, "*.mp4"))
    if not mp4_list:
        raise RuntimeError("No MP4 generated by RecordVideo; check Gymnasium/ffmpeg installation.")
    mp4_path = max(mp4_list, key=os.path.getmtime)
    shutil.move(mp4_path, video_out)
    shutil.rmtree(tmp_dir, ignore_errors=True)

def eval_checkpoint(
    agent,
    env_id: str,
    stage_dir: Path,
    random_rewards_path: str,
    seeds,
    algo: str = "Agent",
    frac_label: str = "",
    make_gif: bool = True,
    gif_fps: int = 15,
    gif_width: int = 640,
):
    """
    Standardized checkpoint evaluation:
      - run 10 episodes on a single env with fixed seeds
      - save trained_rewards.npz
      - save boxplot trained vs random
      - save histogram of trained rewards
      - record an MP4 'rollout.mp4' for the median episode (by reward)
      - (optional) convert MP4 to GIF for README convenience
      - save model snapshot and meta.json (includes global timesteps if available)
    """
    logger = setup_logger("eval_suite")
    stage_dir = Path(stage_dir)
    stage_dir.mkdir(parents=True, exist_ok=True)

    rnd = np.load(random_rewards_path)["rewards"]

    # Run 10 episodes (single env; no render for speed)
    trained_rewards = []
    for s in seeds:
        env = gym.make(env_id)  # single env, no render
        obs, _ = env.reset(seed=s)
        done = False
        ep_reward = 0.0
        while not done:
            action, _ = agent.predict(obs, deterministic=True)
            obs, r, terminated, truncated, _ = env.step(action)
            ep_reward += r
            done = bool(terminated or truncated)
        trained_rewards.append(ep_reward)
        env.close()

    trained_rewards = np.array(trained_rewards, dtype=np.float32)
    np.savez(stage_dir / "trained_rewards.npz", rewards=trained_rewards, seeds=np.array(seeds, dtype=np.int32))
    logger.info(f"[checkpoint] Saved rewards to {stage_dir/'trained_rewards.npz'}")

    # Plots: improved titles/labels
    box_title = _format_title(algo, env_id, frac_label, "Trained vs Random — Reward Distribution")
    hist_title = _format_title(algo, env_id, frac_label, "Distribution of Trained Episodic Returns")

    _plot_box_vs_random(trained_rewards, rnd, str(stage_dir / "boxplot_trained_vs_random.png"), box_title)
    _plot_hist(trained_rewards, str(stage_dir / "trained_rewards_hist.png"), hist_title)

    # Video: record median-episode rollout
    median_idx = int(np.argsort(trained_rewards)[len(trained_rewards)//2])
    median_seed = seeds[median_idx]
    mp4_path = str(stage_dir / "rollout.mp4")
    _record_one_rollout(agent, env_id, seed=median_seed, video_out=mp4_path)
    logger.info(f"[checkpoint] Saved video to {mp4_path}")

    # Optional GIF for README convenience
    if make_gif:
        gif_path = str(stage_dir / "rollout.gif")
        ok = mp4_to_gif(mp4_path, gif_path, fps=gif_fps, width=gif_width)
        if ok:
            logger.info(f"[checkpoint] Saved GIF to {gif_path}")
        else:
            logger.warning("[checkpoint] GIF conversion skipped (ffmpeg not found)")

    # Snapshot model
    agent.save(str(stage_dir / "model.zip"))

    # Meta (also record global timesteps if available)
    meta = {
        "algo": agent.__class__.__name__,
        "env": env_id,
        "n_eval_episodes": len(seeds),
        "seeds": list(seeds),
        "global_timesteps": int(getattr(agent, "num_timesteps", 0)),
        "fraction_label": frac_label,
    }
    (stage_dir / "meta.json").write_text(json.dumps(meta, indent=2))
    logger.info(f"[checkpoint] Wrote meta.json")
